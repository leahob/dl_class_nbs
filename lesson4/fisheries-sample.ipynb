{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter Fisheries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "WARNING (theano.sandbox.cuda): Ignoring call to use(1), GPU number 0 is already in use.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/nbs/lesson4\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup batches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "1. create validation set\n",
    "2. create sample set\n",
    "2. mode to separate dirs for each set\n",
    "3. finetune and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "import math\n",
    "import cPickle as pickle\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "from numpy.random import random, permutation, randn, normal, uniform\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import bcolz\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/fisheries\n"
     ]
    }
   ],
   "source": [
    "%cd \"/home/ubuntu/data/fisheries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/fisheries/train\n"
     ]
    }
   ],
   "source": [
    "%cd train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir ../valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOL\n",
      "YFT\n",
      "BET\n",
      "LAG\n",
      "OTHER\n",
      "NoF\n",
      "ALB\n",
      "SHARK\n"
     ]
    }
   ],
   "source": [
    "for d in glob('*'):\n",
    "    print(d)\n",
    "    os.mkdir('../valid/'+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(400): os.rename(shuf[i], '../valid/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1551 \u001b[01;35mALB\r\n",
      "    183 \u001b[01;35mBET\r\n",
      "    105 \u001b[01;35mDOL\r\n",
      "     56 \u001b[01;35mLAG\r\n",
      "    408 \u001b[01;35mNoF\r\n",
      "    259 \u001b[01;35mOTHER\r\n",
      "    158 \u001b[01;35mSHARK\r\n",
      "    656 \u001b[01;35mYFT\r\n",
      "      1 \u001b[0m\u001b[01;35mALB\r\n"
     ]
    }
   ],
   "source": [
    "%ls -1 */*.jpg | cut -f1 -d\"/\" | sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    167 ALB\r\n",
      "     17 BET\r\n",
      "     12 DOL\r\n",
      "     11 LAG\r\n",
      "     57 NoF\r\n",
      "     40 OTHER\r\n",
      "     18 SHARK\r\n",
      "     78 YFT\r\n"
     ]
    }
   ],
   "source": [
    " ls -1 ../valid/*/*.jpg | cut -f3 -d\"/\" | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  create sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir ../sample\n",
    "%mkdir ../sample/train\n",
    "%mkdir ../sample/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOL\n",
      "YFT\n",
      "BET\n",
      "LAG\n",
      "OTHER\n",
      "NoF\n",
      "ALB\n",
      "SHARK\n"
     ]
    }
   ],
   "source": [
    "for d in glob('*'):\n",
    "    print(d)\n",
    "    os.mkdir('../sample/valid/'+d)\n",
    "    os.mkdir('../sample/train/'+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(400): copyfile(shuf[i], '../sample/train/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    190 ALB\r\n",
      "     13 BET\r\n",
      "     12 DOL\r\n",
      "      4 LAG\r\n",
      "     50 NoF\r\n",
      "     34 OTHER\r\n",
      "     20 SHARK\r\n",
      "     77 YFT\r\n"
     ]
    }
   ],
   "source": [
    " ls -1 ../sample/train/*/*.jpg | cut -f4 -d\"/\" | sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/fisheries/valid\n"
     ]
    }
   ],
   "source": [
    "%cd ../valid\n",
    "g = glob('*/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(100): copyfile(shuf[i], '../sample/valid/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     42 ALB\r\n",
      "      1 BET\r\n",
      "      4 DOL\r\n",
      "      3 LAG\r\n",
      "     23 NoF\r\n",
      "      8 OTHER\r\n",
      "      1 SHARK\r\n",
      "     18 YFT\r\n"
     ]
    }
   ],
   "source": [
    " ls -1 ../sample/valid/*/*.jpg | cut -f4 -d\"/\" | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3377 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "path = '/home/ubuntu/data/fisheries/'\n",
    "batches = get_batches(path+'train', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batches = get_batches(path+'test', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagenet conv features\n",
    "\n",
    "- Small data set similar to imagenet images (full color photos)\n",
    "- Use pre-trained VGG weights\n",
    "- Precompute the output of the last convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.platform.ai/models/vgg16.h5\n",
      "553246720/553482496 [============================>.] - ETA: 0sDownloading data from http://www.platform.ai/models/imagenet_class_index.json\n",
      "24576/35363 [===================>..........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3377 images belonging to 8 classes.\n",
      "Found 400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3377 images belonging to 8 classes.\n",
      "Found 400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
