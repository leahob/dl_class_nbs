{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter Fisheries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "WARNING (theano.sandbox.cuda): Ignoring call to use(1), GPU number 0 is already in use.\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/nbs/lesson4\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/nbs/lesson4\n",
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup batches "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "1. create validation set\n",
    "2. create sample set\n",
    "2. mode to separate dirs for each set\n",
    "3. finetune and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "import math\n",
    "import cPickle as pickle\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "#import cv2\n",
    "from numpy.random import random, permutation, randn, normal, uniform\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy.ndimage import imread\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import bcolz\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/fisheries\n"
     ]
    }
   ],
   "source": [
    "%cd \"/home/ubuntu/data/fisheries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/fisheries/train\n"
     ]
    }
   ],
   "source": [
    "%cd train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../valid’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "%mkdir ../valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOL\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 17] File exists: '../valid/DOL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5da62766b7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../valid/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 17] File exists: '../valid/DOL'"
     ]
    }
   ],
   "source": [
    "for d in glob('*'):\n",
    "    print(d)\n",
    "    os.mkdir('../valid/'+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(400): os.rename(shuf[i], '../valid/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1551 \u001b[01;35mALB\r\n",
      "    183 \u001b[01;35mBET\r\n",
      "    105 \u001b[01;35mDOL\r\n",
      "     56 \u001b[01;35mLAG\r\n",
      "    408 \u001b[01;35mNoF\r\n",
      "    259 \u001b[01;35mOTHER\r\n",
      "    158 \u001b[01;35mSHARK\r\n",
      "    656 \u001b[01;35mYFT\r\n",
      "      1 \u001b[0m\u001b[01;35mALB\r\n"
     ]
    }
   ],
   "source": [
    "%ls -1 */*.jpg | cut -f1 -d\"/\" | sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    167 ALB\r\n",
      "     17 BET\r\n",
      "     12 DOL\r\n",
      "     11 LAG\r\n",
      "     57 NoF\r\n",
      "     40 OTHER\r\n",
      "     18 SHARK\r\n",
      "     78 YFT\r\n"
     ]
    }
   ],
   "source": [
    " ls -1 ../valid/*/*.jpg | cut -f3 -d\"/\" | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  create sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir ../sample\n",
    "%mkdir ../sample/train\n",
    "%mkdir ../sample/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in glob('*'):\n",
    "    print(d)\n",
    "    os.mkdir('../sample/valid/'+d)\n",
    "    os.mkdir('../sample/train/'+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = glob('*/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(400): copyfile(shuf[i], '../sample/train/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    190 ALB\r\n",
      "     13 BET\r\n",
      "     12 DOL\r\n",
      "      4 LAG\r\n",
      "     50 NoF\r\n",
      "     34 OTHER\r\n",
      "     20 SHARK\r\n",
      "     77 YFT\r\n"
     ]
    }
   ],
   "source": [
    " ls -1 ../sample/train/*/*.jpg | cut -f4 -d\"/\" | sort | uniq -c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../valid\n",
    "g = glob('*/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(100): copyfile(shuf[i], '../sample/valid/'+shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     42 ALB\r\n",
      "      1 BET\r\n",
      "      4 DOL\r\n",
      "      3 LAG\r\n",
      "     23 NoF\r\n",
      "      8 OTHER\r\n",
      "      1 SHARK\r\n",
      "     18 YFT\r\n"
     ]
    }
   ],
   "source": [
    " ls -1 ../sample/valid/*/*.jpg | cut -f4 -d\"/\" | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3377 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "path = '/home/ubuntu/data/fisheries/'\n",
    "batches = get_batches(path+'train', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(path+'test', batch_size=batch_size*2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagenet conv features\n",
    "\n",
    "- Small data set similar to imagenet images (full color photos)\n",
    "- Use pre-trained VGG weights\n",
    "- Precompute the output of the last convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()\n",
    "model = vgg.model\n",
    "last_conv_idx = [i for i,l in enumerate(model.layers) if type(l) is Convolution2D][-1]\n",
    "conv_layers = model.layers[:last_conv_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3377 images belonging to 8 classes.\n",
      "Found 400 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/data/fisheries/results/conv_val_feat.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0cc764a6f4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mconv_val_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconv_test_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'results/conv_val_feat.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_val_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'results/conv_test_feat.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_test_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'results/conv_feat.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mutils.pyc\u001b[0m in \u001b[0;36msave_array\u001b[0;34m(fname, arr)\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.__cinit__ (bcolz/carray_ext.c:13370)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._create_carray (bcolz/carray_ext.c:14947)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray._mkdirs (bcolz/carray_ext.c:16908)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/data/fisheries/results/conv_val_feat.dat'"
     ]
    }
   ],
   "source": [
    "conv_feat = conv_model.predict_generator(batches, batches.nb_sample)\n",
    "conv_val_feat = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "conv_test_feat = conv_model.predict_generator(test_batches, test_batches.nb_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir /home/ubuntu/data/fisheries/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_val_feat.dat', conv_val_feat)\n",
    "save_array(path+'results/conv_test_feat.dat', conv_test_feat)\n",
    "save_array(path+'results/conv_feat.dat', conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 512, 14, 14)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchnorm dense layers on pretrained conv layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_maxpool_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(8, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_avgpool_bn_layers(p):\n",
    "    return [\n",
    "        AveragePooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(8, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_mp_model = Sequential(get_maxpool_bn_layers(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_mp_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3377, 512, 14, 14)\n",
      "(400, 512, 14, 14)\n",
      "(3377, 8)\n",
      "(400, 8)\n"
     ]
    }
   ],
   "source": [
    "print(conv_feat.shape)\n",
    "print(conv_val_feat.shape)\n",
    "print(trn_labels.shape)\n",
    "print(val_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3377 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "3377/3377 [==============================] - 1s - loss: 3.3323 - acc: 0.2005 - val_loss: 2.3482 - val_acc: 0.2275\n",
      "Epoch 2/10\n",
      "3377/3377 [==============================] - 1s - loss: 2.7578 - acc: 0.2701 - val_loss: 1.9607 - val_acc: 0.3550\n",
      "Epoch 3/10\n",
      "3377/3377 [==============================] - 1s - loss: 2.4693 - acc: 0.3003 - val_loss: 1.8229 - val_acc: 0.3925\n",
      "Epoch 4/10\n",
      "3377/3377 [==============================] - 1s - loss: 2.2200 - acc: 0.3367 - val_loss: 1.8728 - val_acc: 0.3525\n",
      "Epoch 5/10\n",
      "3377/3377 [==============================] - 1s - loss: 2.1112 - acc: 0.3550 - val_loss: 1.8612 - val_acc: 0.3900\n",
      "Epoch 6/10\n",
      "3377/3377 [==============================] - 1s - loss: 2.0193 - acc: 0.3752 - val_loss: 1.8514 - val_acc: 0.4000\n",
      "Epoch 7/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.8975 - acc: 0.3906 - val_loss: 1.8119 - val_acc: 0.4025\n",
      "Epoch 8/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.8482 - acc: 0.4158 - val_loss: 1.7925 - val_acc: 0.4125\n",
      "Epoch 9/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.7592 - acc: 0.4317 - val_loss: 1.7936 - val_acc: 0.4050\n",
      "Epoch 10/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.7151 - acc: 0.4466 - val_loss: 1.7922 - val_acc: 0.4075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe745ea40d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_mp_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bn_mp_model.save_weights(path + 'models/bn_mp_epoch1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import AveragePooling2D\n",
    "bn_ap_model = Sequential(get_avgpool_bn_layers(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_ap_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3377 samples, validate on 400 samples\n",
      "Epoch 1/10\n",
      "3377/3377 [==============================] - 1s - loss: 2.9269 - acc: 0.1685 - val_loss: 2.1919 - val_acc: 0.2825\n",
      "Epoch 2/10\n",
      "3377/3377 [==============================] - 1s - loss: 2.2909 - acc: 0.2550 - val_loss: 1.9376 - val_acc: 0.3700\n",
      "Epoch 3/10\n",
      "3377/3377 [==============================] - 1s - loss: 2.0474 - acc: 0.3364 - val_loss: 1.9123 - val_acc: 0.3950\n",
      "Epoch 4/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.8870 - acc: 0.3728 - val_loss: 1.8241 - val_acc: 0.4225\n",
      "Epoch 5/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.7467 - acc: 0.4134 - val_loss: 1.8295 - val_acc: 0.3975\n",
      "Epoch 6/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.7038 - acc: 0.4229 - val_loss: 1.8779 - val_acc: 0.3825\n",
      "Epoch 7/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.6370 - acc: 0.4424 - val_loss: 1.8631 - val_acc: 0.4100\n",
      "Epoch 8/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.5724 - acc: 0.4519 - val_loss: 1.8490 - val_acc: 0.4000\n",
      "Epoch 9/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.5147 - acc: 0.4696 - val_loss: 1.8966 - val_acc: 0.3800\n",
      "Epoch 10/10\n",
      "3377/3377 [==============================] - 1s - loss: 1.4615 - acc: 0.4889 - val_loss: 1.9057 - val_acc: 0.3875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe72ee1b290>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_ap_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=10, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-computed data augmentation + dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3377 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "da_batches = get_batches(path+'train', gen_t, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use image data generator to create a dataset of conv features 5x larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = conv_model.predict_generator(da_batches, da_batches.nb_sample*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/da_conv_feat.dat', da_conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Combine real training data with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = np.concatenate([da_conv_feat, conv_feat])\n",
    "da_trn_labels = np.concatenate([trn_labels]*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_mp_da_model = Sequential(get_maxpool_bn_layers(p))\n",
    "bn_mp_da_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20262 samples, validate on 400 samples\n",
      "Epoch 1/4\n",
      "20262/20262 [==============================] - 8s - loss: 3.4739 - acc: 0.2554 - val_loss: 0.8956 - val_acc: 0.7725\n",
      "Epoch 2/4\n",
      "20262/20262 [==============================] - 8s - loss: 2.2967 - acc: 0.4430 - val_loss: 0.6251 - val_acc: 0.8400\n",
      "Epoch 3/4\n",
      "20262/20262 [==============================] - 8s - loss: 1.7767 - acc: 0.5556 - val_loss: 0.5871 - val_acc: 0.8625\n",
      "Epoch 4/4\n",
      "20262/20262 [==============================] - 9s - loss: 1.4659 - acc: 0.6341 - val_loss: 0.6163 - val_acc: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe733a08ed0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_mp_da_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bn_ap_da_model = Sequential(get_avgpool_bn_layers(p))\n",
    "bn_ap_da_model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20262 samples, validate on 400 samples\n",
      "Epoch 1/2\n",
      "20262/20262 [==============================] - 10s - loss: 3.2813 - acc: 0.3036 - val_loss: 0.7090 - val_acc: 0.8150\n",
      "Epoch 2/2\n",
      "20262/20262 [==============================] - 9s - loss: 2.0364 - acc: 0.5215 - val_loss: 0.5015 - val_acc: 0.8575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe722d16d90>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_ap_da_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and submit predictions from bn_mp_da, bn_ap_da models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mp_preds = bn_mp_da_model.predict(conv_test_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap_preds = bn_ap_da_model.predict(conv_test_feat, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_filenames = test_batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknown/img_06893.jpg',\n",
       " 'unknown/img_02082.jpg',\n",
       " 'unknown/img_06261.jpg',\n",
       " 'unknown/img_03628.jpg',\n",
       " 'unknown/img_04860.jpg',\n",
       " 'unknown/img_01640.jpg',\n",
       " 'unknown/img_02709.jpg',\n",
       " 'unknown/img_00030.jpg',\n",
       " 'unknown/img_04740.jpg']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_filenames[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ap_submit = pd.DataFrame(ap_preds, columns=classes)\n",
    "ap_submit.insert(0, 'image', [a[8:] for a in test_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_06237.jpg</td>\n",
       "      <td>0.355891</td>\n",
       "      <td>0.040566</td>\n",
       "      <td>0.059308</td>\n",
       "      <td>0.026525</td>\n",
       "      <td>0.063588</td>\n",
       "      <td>0.037628</td>\n",
       "      <td>0.031134</td>\n",
       "      <td>0.385359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_06893.jpg</td>\n",
       "      <td>0.603492</td>\n",
       "      <td>0.033006</td>\n",
       "      <td>0.034771</td>\n",
       "      <td>0.018863</td>\n",
       "      <td>0.082407</td>\n",
       "      <td>0.037342</td>\n",
       "      <td>0.027252</td>\n",
       "      <td>0.162867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02082.jpg</td>\n",
       "      <td>0.198528</td>\n",
       "      <td>0.037253</td>\n",
       "      <td>0.044142</td>\n",
       "      <td>0.027116</td>\n",
       "      <td>0.411799</td>\n",
       "      <td>0.035010</td>\n",
       "      <td>0.124108</td>\n",
       "      <td>0.122044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_06261.jpg</td>\n",
       "      <td>0.510785</td>\n",
       "      <td>0.032529</td>\n",
       "      <td>0.021745</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.066152</td>\n",
       "      <td>0.039928</td>\n",
       "      <td>0.023479</td>\n",
       "      <td>0.286716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_03628.jpg</td>\n",
       "      <td>0.621451</td>\n",
       "      <td>0.022591</td>\n",
       "      <td>0.033991</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.062703</td>\n",
       "      <td>0.053016</td>\n",
       "      <td>0.032269</td>\n",
       "      <td>0.153825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_06237.jpg  0.355891  0.040566  0.059308  0.026525  0.063588  0.037628   \n",
       "1  img_06893.jpg  0.603492  0.033006  0.034771  0.018863  0.082407  0.037342   \n",
       "2  img_02082.jpg  0.198528  0.037253  0.044142  0.027116  0.411799  0.035010   \n",
       "3  img_06261.jpg  0.510785  0.032529  0.021745  0.018666  0.066152  0.039928   \n",
       "4  img_03628.jpg  0.621451  0.022591  0.033991  0.020155  0.062703  0.053016   \n",
       "\n",
       "      SHARK       YFT  \n",
       "0  0.031134  0.385359  \n",
       "1  0.027252  0.162867  \n",
       "2  0.124108  0.122044  \n",
       "3  0.023479  0.286716  \n",
       "4  0.032269  0.153825  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/fisheries/\n"
     ]
    }
   ],
   "source": [
    "ap_submit_name = path+'results/ap_submit.csv'\n",
    "ap_submit.to_csv(ap_submit_name, index=False)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='../../data/fisheries/results/ap_submit.csv' target='_blank'>../../data/fisheries/results/ap_submit.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/data/fisheries/results/ap_submit.csv"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('../../data/fisheries/results/ap_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mp_submit = pd.DataFrame(mp_preds, columns=classes)\n",
    "mp_submit.insert(0, 'image', [a[8:] for a in test_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_06237.jpg</td>\n",
       "      <td>0.362001</td>\n",
       "      <td>0.035319</td>\n",
       "      <td>0.020658</td>\n",
       "      <td>0.040183</td>\n",
       "      <td>0.062452</td>\n",
       "      <td>0.052852</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.400528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_06893.jpg</td>\n",
       "      <td>0.567150</td>\n",
       "      <td>0.033538</td>\n",
       "      <td>0.032001</td>\n",
       "      <td>0.027656</td>\n",
       "      <td>0.055870</td>\n",
       "      <td>0.068604</td>\n",
       "      <td>0.041292</td>\n",
       "      <td>0.173889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_02082.jpg</td>\n",
       "      <td>0.487445</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.013801</td>\n",
       "      <td>0.031727</td>\n",
       "      <td>0.176708</td>\n",
       "      <td>0.028245</td>\n",
       "      <td>0.114046</td>\n",
       "      <td>0.131829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_06261.jpg</td>\n",
       "      <td>0.644842</td>\n",
       "      <td>0.018643</td>\n",
       "      <td>0.011207</td>\n",
       "      <td>0.014032</td>\n",
       "      <td>0.023648</td>\n",
       "      <td>0.038594</td>\n",
       "      <td>0.014768</td>\n",
       "      <td>0.234266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_03628.jpg</td>\n",
       "      <td>0.749803</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>0.015827</td>\n",
       "      <td>0.013549</td>\n",
       "      <td>0.027336</td>\n",
       "      <td>0.044968</td>\n",
       "      <td>0.014604</td>\n",
       "      <td>0.120486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image       ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_06237.jpg  0.362001  0.035319  0.020658  0.040183  0.062452  0.052852   \n",
       "1  img_06893.jpg  0.567150  0.033538  0.032001  0.027656  0.055870  0.068604   \n",
       "2  img_02082.jpg  0.487445  0.016200  0.013801  0.031727  0.176708  0.028245   \n",
       "3  img_06261.jpg  0.644842  0.018643  0.011207  0.014032  0.023648  0.038594   \n",
       "4  img_03628.jpg  0.749803  0.013427  0.015827  0.013549  0.027336  0.044968   \n",
       "\n",
       "      SHARK       YFT  \n",
       "0  0.026007  0.400528  \n",
       "1  0.041292  0.173889  \n",
       "2  0.114046  0.131829  \n",
       "3  0.014768  0.234266  \n",
       "4  0.014604  0.120486  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/data/fisheries/\n"
     ]
    }
   ],
   "source": [
    "mp_submit_name = path+'results/mp_submit.csv'\n",
    "mp_submit.to_csv(mp_submit_name, index=False)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='../../data/fisheries/results/mp_submit.csv' target='_blank'>../../data/fisheries/results/mp_submit.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/data/fisheries/results/mp_submit.csv"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink('../../data/fisheries/results/mp_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
